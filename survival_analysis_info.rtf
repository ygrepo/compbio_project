{\rtf1\ansi\ansicpg1252\cocoartf2708
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa240\partightenfactor0

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In survival analysis, the hazard ratio (HR) is a measure of the relative risk of experiencing an event between two groups. It is often used in studies where the primary endpoint is time to an event, such as death, disease recurrence, or progression.\
The HR is the ratio of the hazard rates (i.e., the instantaneous event rates) between two groups, usually a treatment group and a control group. An HR of 1 indicates no difference in the hazard rates between the two groups, while an HR greater than 1 indicates that the treatment group has a higher hazard rate (i.e., a higher risk of experiencing the event) than the control group, and an HR less than 1 indicates that the treatment group has a lower hazard rate (i.e., a lower risk of experiencing the event) than the control group.\
For example, an HR of 2 means that the treatment group has twice the hazard rate (i.e., twice the risk) of the control group. Similarly, an HR of 0.5 means that the treatment group has half the hazard rate (i.e., half the risk) of the control group.\
HR is often used in survival analysis to compare the effectiveness of different treatments or interventions or to identify risk factors associated with the occurrence of an event. It is typically estimated using Cox proportional hazards regression or other survival regression models.\
}